from langchain_community.vectorstores import Qdrant
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.retrievers import EnsembleRetriever
from langchain.prompts import PromptTemplate
from qdrant_client import QdrantClient

# Ayarlar
QDRANT_URL = "http://localhost:6333"
INSTR_COLLECTION = "n61_instructions"
PRODUCT_COLLECTION = "product_info"
EMBED_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
GROQ_API_KEY = "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" # GerÃ§ek API anahtarÄ±nÄ±zÄ± buraya koyun
LLM_MODEL = "llama3-70b-8192"

# TÃ¼rkÃ§e cevap vermesi ve asistan rolÃ¼nÃ¼ Ã¼stlenmesi iÃ§in Ã¶zel prompt ÅŸablonu
TURKISH_PROMPT_TEMPLATE = """
Sen N61 AlÄ±ÅŸveriÅŸ AsistanÄ±sÄ±n. GÃ¶revin, sana verilen baÄŸlamdaki Ã¼rÃ¼n ve bilgileri kullanarak kullanÄ±cÄ±nÄ±n sorularÄ±nÄ± yanÄ±tlamak ve ona yardÄ±mcÄ± olmaktÄ±r.

Kurallar:
- Kesinlikle stok adedi, Ã¼rÃ¼n sayÄ±sÄ± veya "ÅŸu anda X Ã¼rÃ¼n var" gibi ifadeler kullanma.
- Bir kategori sorulduÄŸunda Ã¶nce yalnÄ±zca bir Ã¼rÃ¼nÃ¼ kÄ±saca tanÄ±t, ardÄ±ndan "Bu tarzdan hoÅŸlanÄ±r mÄ±sÄ±nÄ±z?" diye sor.
- KullanÄ±cÄ± "beÄŸenmedim / hoÅŸlanmadÄ±m" derse, aynÄ± kategoriden farklÄ± bir Ã¼rÃ¼nÃ¼ Ã¶ner.
- ÃœrÃ¼n aÃ§Ä±klamalarÄ±nda fiyat, kumaÅŸ ve kullanÄ±m mevsimi gibi en fazla 2-3 Ã¶zellik ver; liste yapma, kÄ±sa paragraf yeterli.
- Kampanya bilgisi baÄŸlamda yoksa "Åu anda aktif kampanya bilgim yok" de.
- Beden sorularÄ±nda Ã¶lÃ§Ã¼ iste, iade sorularÄ±nda prosedÃ¼rÃ¼ aÃ§Ä±kla.
- SorularÄ± her zaman TÃ¼rkÃ§e yanÄ±tla.
- CevabÄ±n sadece verilen baÄŸlama dayanmalÄ±. EÄŸer baÄŸlamda cevap yoksa, "Bu konuda bilgi bulamadÄ±m, Ã¼zgÃ¼nÃ¼m." de.

BaÄŸlam:
{context}

Soru: {question}

Cevap (TÃ¼rkÃ§e):
"""

TURKISH_PROMPT = PromptTemplate(
    template=TURKISH_PROMPT_TEMPLATE, input_variables=["context", "question"]
)

# 1. Embedding Modeli
# HuggingFace hub'Ä±ndan modelimizi yÃ¼klÃ¼yoruz.
embeddings = HuggingFaceEmbeddings(
    model_name=EMBED_MODEL,
    model_kwargs={'device': 'cpu'} # CPU Ã¼zerinde Ã§alÄ±ÅŸmasÄ± iÃ§in
)

# 2. Qdrant Client ve Vector Store'lar
# Langchain'in Qdrant entegrasyonunu kullanarak iki farklÄ± koleksiyon iÃ§in baÄŸlantÄ± kuruyoruz.
client = QdrantClient(url=QDRANT_URL)

instr_store = Qdrant(
    client=client,
    collection_name=INSTR_COLLECTION,
    embeddings=embeddings,
    content_payload_key="content",
)

product_store = Qdrant(
    client=client,
    collection_name=PRODUCT_COLLECTION,
    embeddings=embeddings,
    content_payload_key="content",
)

# 3. Retriever'lar
# ArtÄ±k hibrit arama yapmadÄ±ÄŸÄ±mÄ±z iÃ§in search_type'Ä± belirtmiyoruz (varsayÄ±lan dense).
instr_retriever = instr_store.as_retriever(search_kwargs={"k": 3})
product_retriever = product_store.as_retriever(search_kwargs={"k": 1})

# 4. Ensemble Retriever
# Ä°ki retriever'Ä± birleÅŸtirerek tek bir sorguyla iki koleksiyonda da arama yapmayÄ± saÄŸlÄ±yoruz.
# AÄŸÄ±rlÄ±klar, hangi retriever'Ä±n sonuÃ§larÄ±nÄ±n daha Ã¶ncelikli olacaÄŸÄ±nÄ± belirler.
ensemble_retriever = EnsembleRetriever(
    retrievers=[instr_retriever, product_retriever],
    weights=[0.4, 0.6] # ÃœrÃ¼n aramasÄ±na biraz daha fazla Ã¶ncelik veriyoruz
)

# 5. Sohbet GeÃ§miÅŸi (Memory)
# Modelin Ã¶nceki konuÅŸmalarÄ± hatÄ±rlamasÄ± iÃ§in hafÄ±za mekanizmasÄ±.
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    output_key='result'
)

# 6. Groq LLM
llm = ChatGroq(
    temperature=0.2,
    model_name=LLM_MODEL,
    api_key=GROQ_API_KEY
)

# 7. RetrievalQA Zinciri
# TÃ¼m parÃ§alarÄ± bir araya getiren ana RAG zinciri.
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=ensemble_retriever,
    memory=memory,
    chain_type_kwargs={"prompt": TURKISH_PROMPT} # Ã–zel TÃ¼rkÃ§e prompt'u burada zincire dahil ediyoruz
)

# 8. Sohbet DÃ¶ngÃ¼sÃ¼
def chat_loop():
    print("ğŸ¤– Merhaba! Ben N61 AlÄ±ÅŸveriÅŸ AsistanÄ±. NasÄ±l yardÄ±mcÄ± olabilirim?")
    print("âœ‹ Ã‡Ä±kmak iÃ§in boÅŸ bÄ±rak ve ENTER'a bas.")
    while True:
        question = input("\nSen: ")
        if not question.strip():
            break

        try:
            response = qa_chain.invoke({"query": question})
            print(f"ğŸ¤–: {response['result']}")
        except Exception as e:
            print(f"Bir hata oluÅŸtu: {e}")

if __name__ == "__main__":
    chat_loop() 